{
 "cells": [
  {
   "source": [
    "# Prepare data\n",
    "\n",
    "Import data and create train/test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import Titanic data\n",
    "df = pd.read_csv(\"../data/titanicDataSet.csv\")\n",
    "\n",
    "# drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# choose only columns we may want to use in Analysis\n",
    "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Boarded']]\n",
    "\n",
    "# choose only columns where data is complete for all features\n",
    "df = df[(df['Pclass'].notnull()) & (df['Age'].notnull()) & (df['SibSp'].notnull()) & (df['Parch'].notnull()) & (df['Fare'].notnull()) & (df['Boarded'].notnull()) & (df['Sex'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/test Set\n",
    "df_train = df[df['Survived'].notnull()]\n",
    "df_test = df[df['Survived'].isnull()]\n",
    "\n",
    "# set features and target\n",
    "X_train = df_train.drop('Survived', axis=1)\n",
    "y_train = df_train['Survived']\n",
    "X_test = df_test.drop('Survived', axis=1)\n",
    "y_test = df_test['Survived']\n",
    "feature_column_names = X_train.columns\n",
    "\n",
    "# get indices for train/test sets\n",
    "index_values_train = X_train.index\n",
    "index_values_test = X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Owen\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# separate categorical and numeric data to encode categorical data\n",
    "categorical_X_train = df_train[['Sex', 'Boarded']]\n",
    "numeric_X_train = df_train[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "categorical_X_test = df_test[['Sex', 'Boarded']]\n",
    "numeric_X_test = df_test[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "\n",
    "# encode categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(categorical_X_train)\n",
    "cat_encoded_X_train = ordinal_encoder.transform(categorical_X_train)\n",
    "cat_encoded_X_test = ordinal_encoder.transform(categorical_X_test)\n",
    "\n",
    "# make categorical dataframes to join with numeric dataframes\n",
    "cat_encoded_X_train = pd.DataFrame(data = cat_encoded_X_train, index = index_values_train, columns = ['Sex', 'Boarded'])\n",
    "cat_encoded_X_test = pd.DataFrame(data = cat_encoded_X_test, index = index_values_test, columns = ['Sex', 'Boarded'])\n",
    "\n",
    "# join categorical encoded data with numeric data\n",
    "encoded_X_train = numeric_X_train.join(cat_encoded_X_train)\n",
    "encoded_X_test = numeric_X_test.join(cat_encoded_X_test)\n",
    "\n",
    "# encode train target values\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "\n",
    "# scale X data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(encoded_X_train)\n",
    "X_train_scaled = X_scaler.transform(encoded_X_train)\n",
    "X_test_scaled = X_scaler.transform(encoded_X_test)"
   ]
  },
  {
   "source": [
    "# Optimize the model features\n",
    "\n",
    "Find the features that affect the model output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Selection\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.feature_selection import RFE\n",
    "model = SVC(kernel='linear')\n",
    "selector = RFE(model, n_features_to_select=7, step=1)\n",
    "selector = selector.fit(X_train_scaled, y_train)\n",
    "ss = selector.support_\n",
    "selectedFeatures = list(feature_column_names[ss])\n",
    "\n",
    "# make X of only important parameters\n",
    "X_train = X_train[selectedFeatures]\n",
    "X_test = X_test[selectedFeatures]\n",
    "\n",
    "# rescale to X of only important parameters\n",
    "X_scaler = MinMaxScaler().fit(encoded_X_train)\n",
    "X_train_scaled = X_scaler.transform(encoded_X_train)\n",
    "X_test_scaled = X_scaler.transform(encoded_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "Score the model without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Acc: 0.780\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# model accuracy\n",
    "print('Train Acc: %.3f' % model.score(X_train_scaled, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10], 'degree': [2, 3],\n",
       "                         'gamma': ['scale', 'auto']})"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# create the GridSearchCV model from SVC model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "                'gamma':['scale', 'auto'],\n",
    "                'degree': [2,3],\n",
    "                'C':[1, 5, 10]\n",
    "            }\n",
    "# train the model with GridSearch\n",
    "grid = GridSearchCV(model, parameters)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "source": [
    "# Train the Model\n",
    "\n",
    "Score the model with hyperparameter tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Acc: 0.780\n              precision    recall  f1-score   support\n\n    Survived       0.79      0.85      0.82       424\n    Deceased       0.75      0.68      0.72       290\n\n    accuracy                           0.78       714\n   macro avg       0.77      0.76      0.77       714\nweighted avg       0.78      0.78      0.78       714\n\n"
     ]
    }
   ],
   "source": [
    "# get parameters to optimize SVC model\n",
    "bestParamsDict = grid.best_params_\n",
    "bestModel = SVC(kernel='linear', gamma=bestParamsDict['gamma'], C=bestParamsDict['C'], degree=bestParamsDict['degree'])\n",
    "bestModel.fit(X_train_scaled, y_train)\n",
    "\n",
    "# model Accuracy\n",
    "print('Train Acc: %.3f' % bestModel.score(X_train_scaled, y_train))\n",
    "\n",
    "# calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true = y_train, y_pred = bestModel.predict(X_train_scaled), target_names=['Survived', 'Deceased']))"
   ]
  },
  {
   "source": [
    "# Predict output for test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframes with indices associated with numeric data\n",
    "encoded_X_train = pd.DataFrame(data = X_train_scaled, index = index_values_train, columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Boarded'])\n",
    "encoded_X_test = pd.DataFrame(data = X_test_scaled, index = index_values_test, columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Boarded'])\n",
    "\n",
    "# combine test and train set to predict all values\n",
    "encoded_X = encoded_X_train.append(encoded_X_test)\n",
    "encoded_X = encoded_X.sort_index(axis=0)\n",
    "y_pred = bestModel.predict(encoded_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predicted column to original data\n",
    "df['predicted_survival'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "df.to_csv('svm_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}